{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Beginner Exercises - Iris Dataset","version":"0.3.2","provenance":[{"file_id":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/eager/custom_training_walkthrough.ipynb","timestamp":1557934375315}],"private_outputs":true,"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"yAMY7EYLKgVr","colab_type":"text"},"source":["#**Beginner Exercises: Iris Dataset**\n","Solving the Iris Dataset using Tensorflow 2.0\n","\n","Link to source guide [HERE](https://www.tensorflow.org/tutorials/eager/custom_training_walkthrough)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1J3AuPBT9gyR"},"source":["### Imports and Eager Execution\n","\n","Imports\n","\n","\n","*  OS: Operating system interfaces\n","* Tensorflow 2.0\n","\n","\n","Note here how Eager Execution is enable by default. We didn't need to type any code to enable it. \n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"g4Wzg69bnwK2","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","!pip install -q tensorflow==2.0.0-alpha0\n","\n","import os\n","import tensorflow as tf\n","\n","\n","print(\"TensorFlow version: {}\".format(tf.__version__))\n","print(\"Eager execution: {}\".format(tf.executing_eagerly()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3Px6KAg0Jowz"},"source":["### Download the dataset\n","\n","Download the training dataset file using the [tf.keras.utils.get_file](https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file) function. This returns the file path of the downloaded file.\n","\n","Dataset URL: https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"J6c7uEU9rjRM","colab":{}},"source":["train_dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n","\n","train_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(train_dataset_url),\n","                                           origin=train_dataset_url)\n","\n","print(\"Local copy of the dataset file: {}\".format(train_dataset_fp))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qnX1-aLors4S"},"source":["### Inspect and the data\n","\n","Check the head of our CSV file to understand what our data looks like. Note that: \n","\n","\n","*   We have 120 samples\n","*   Each sample has 4 features (Sepal/Petal length + width)\n","* 3 Classes: Setosa, Versicolor, Virginica\n","\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FQvb_JYdrpPm","colab":{}},"source":["!head -n5 {train_dataset_fp}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kQhzD6P-uBoq"},"source":["##Separate  our data into Features and Labels\n","Using the dataset, we'll need to define our features, labels, and classes to pass into our machine learning model. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9Edhevw7exl6","colab":{}},"source":["# column order in CSV file\n","column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n","class_names = ['Setosa', 'Versicolor', 'Virginica']\n","\n","feature_names = column_names[:-1]\n","label_name = column_names[-1]\n","\n","print(\"Features: {}\".format(feature_names))\n","print(\"Label: {}\".format(label_name))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dqPkQExM2Pwt"},"source":["### Create a `tf.data.Dataset`\n","\n","New to Tensorflow 2.0 is the [tf.data.experimenta.make_csv_dataset](https://www.tensorflow.org/api_docs/python/tf/data/experimental/make_csv_dataset) API. We'll use this API to create a dataset from our CSV.\n","\n","We'll need to define:\n","  * Location of the data\n","  * Batch size (set this to 100)\n","  * Column names\n","  * Label names\n","  * Number of Epochs (set this to 1)\n","\n","We have 120 samples in our dataset. tf.data will build a dataset with X number of samples per batch. By setting our batch size to 100, our tf.data.dataset will have two total batches: Batch1 = 100 samples, Batch2 = 20 samples. This is important for later. \n","\n","The number of Epochs specifies how many times our dataset is repeated in our tf.data.dataset. By setting it to 1 we only use our data once. No repeating. (It's set to repeat forever by default.)\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WsxHnz1ebJ2S","colab":{}},"source":["dataset = tf.data.experimental.make_csv_dataset(\n","    train_dataset_fp,\n","    batch_size = 100,\n","    column_names=column_names,\n","    label_name=label_name,\n","    num_epochs=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gB_RSn62c-3G"},"source":["Because tf 2.0 has eager execution enabled by default we can iterate  through the dataset we just created and return our features and labels. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iDuG94H-C122","colab":{}},"source":["features, labels = next(iter(dataset))\n","\n","features"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YlxpSyHlhT6M"},"source":["###Format our Dataset\n","\n","Notice how our features are ordered dictionaries. \n","\n","We are going to 'stack' our features/labels into a single array with shape: `(batch_size, num_features)`.\n","\n","This function uses the [tf.stack](https://www.tensorflow.org/api_docs/python/tf/stack) method which takes values from a list of tensors and creates a combined tensor at the specified dimension."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jm932WINcaGU","colab":{}},"source":["def pack_features_vector(features, labels):\n","  #Pack the features into a single array.\n","  features = tf.stack(list(features.values()), axis=1)\n","  return features, labels"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"V1Vuph_eDl8x"},"source":["Then use the [tf.data.Dataset.map](https://www.tensorflow.org/api_docs/python/tf/data/dataset/map) method to pack the `features` of each `(features,label)` pair into the training dataset.\n","\n","The map function will take a predefined function (pack_features_vector) and apply it to a dataset. \n","\n","After mapping  our function onto the dataset, we also want to split the dataset into training and testing. We'll do this by grabbing batches of our dataset using [.take and .skip](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#take)\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZbDkzGZIkpXf","colab":{}},"source":["dataset = dataset.map(pack_features_vector)\n","\n","train_dataset = dataset.take(1)\n","test_dataset = dataset.skip(1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NLy0Q1xCldVO"},"source":["The features element of the `Dataset` are now arrays with shape `(batch_size, num_features)`. Let's define our features, labels, test features, and test labels **and** look at the first five examples:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kex9ibEek6Tr","colab":{}},"source":["features, labels = next(iter(train_dataset))\n","test_features, test_labels = next(iter(test_dataset))\n","features[:5]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AZoApR4JtL-H","colab_type":"text"},"source":["##Building our model"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"W23DIMVPQEBt"},"source":["### Create a model using Keras\n","\n","Here we are using [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras) to build our neural network.\n","\n","\n","The [tf.keras.Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model is a linear stack of layers. Its constructor takes a list of layer instances, in this case, two [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layers with 10 nodes each, and an output layer with 3 nodes representing our label predictions. The first layer's `input_shape` parameter corresponds to the number of features from the dataset and is required.\n","\n","Here we'll need to define \n","\n","\n","1.   Input Layer (hint: needs to be the shape of our features)\n","2.   Hidden layer\n","3.  Output layer (hint: needs to be the shape of our labels)\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2fZ6oL2ig3ZK","colab":{}},"source":["model = tf.keras.Sequential([\n","  tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # input shape required\n","  tf.keras.layers.Dense(10, activation=tf.nn.relu),\n","  tf.keras.layers.Dense(3, activation='softmax')\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FHcbEzMpxbHL"},"source":["[Activation function](https://developers.google.com/machine-learning/crash-course/glossary#activation_function): determines the output shape of each node in the layer. These non-linearities are important—without them the model would be equivalent to a single layer.  [ReLU](https://developers.google.com/machine-learning/crash-course/glossary#ReLU) is common for hidden layers.\n","\n","The ideal number of hidden layers and neurons depends on the problem and the dataset. Like many aspects of machine learning, picking the best shape of the neural network requires a mixture of knowledge and experimentation. As a rule of thumb, increasing the number of hidden layers and neurons typically creates a more powerful model, which requires more data to train effectively.\n","\n","[Softmax Activation](https://www.tensorflow.org/versions/r1.8/api_docs/cc/class/tensorflow/ops/softmax?hl=en) will calculate the probabilities of each target class over all possible target classes. Later the calculated probabilities will be helpful for determining the target class for the given inputs"]},{"cell_type":"markdown","metadata":{"id":"s3FStWwVWdEN","colab_type":"text"},"source":["###Compile the Model\n","\n","The[ compile funciton](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#compile) simply configures our model for training. It is here we'll define things like \n","  * Optimizer\n","  * Loss Function\n","  * Metrices\n","  \n","For our model we are going to use the [Adam Optimizer](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/optimizers/Adam). This optimizer uses [Stochastic Optimization](https://arxiv.org/abs/1412.6980) to update the weights in our network.\n","\n","Our Loss Function will use [sparse categorical crossentropy](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/losses/SparseCategoricalCrossentropy). This computes the crossentropy loss between the labels and predictions. We use this crossentropy loss function when there are two or more label classes. \n","\n","Finally, for the metric we'll define accuracy to determine how well our model predictions are compared to the actual class. \n","  "]},{"cell_type":"code","metadata":{"id":"W4UEZLfqY1VN","colab_type":"code","colab":{}},"source":["model.compile(optimizer='Adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2wFKnhWCpDSS"},"source":["### Using the model before training\n","\n","Let's examine what our Neural Network does before we train  it. \n","\n","First let's pass in our features into the model and look at the predictions. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xe6SQ5NrpB-I","colab":{}},"source":["model_preds = model.predict_classes(test_features)\n","\n","\n","print(\"Model Predictions: {}\".format(model_preds))\n","print(\"Actual Classes:    {}\".format(test_labels))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7iuVdNHr61np"},"source":["Pretty bad accuracy, you can see that our model just guessed the same class. That's understandable since it hasn't learned anything yet. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Vzq2E5J2QMtw"},"source":["## Train the model\n","\n","*[Training](https://developers.google.com/machine-learning/crash-course/glossary#training)* is the stage of machine learning when the model is gradually optimized, or the model *learns* the dataset. After training, our model should have better predictions than what we've seen above.\n","\n","Do Note: if your model learns *too much* about the training dataset, then the predictions only work for the data it has seen and will not be generalizable. This problem is called *[overfitting](https://developers.google.com/machine-learning/crash-course/glossary#overfitting)*—it's like memorizing the answers instead of understanding how to solve a problem.\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7Y2VSELvwAvW"},"source":["### Training loop\n","\n","To train our model, we use [model.fit](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#fit). For our model we'll need to define:\n","  * Features\n","  * Labels\n","  * Steps per Epoch\n","  * Epoch\n","  \n","Remember `Epochs` refer to how many times we're going to 'show' our model the data. \n","\n","`steps_per_epoch` refer to how many steps (batches of samples) before moving to the next epoch. \n","\n","Feel free to play around with these values and see how they affect the performance of the model "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AIgulGRUhpto","colab":{}},"source":["model.fit(x=features,\n","          y=labels,\n","          steps_per_epoch=20,\n","          epochs = 10,\n","              )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Zg8GoMZhLpGH"},"source":["## Evaluate the model's effectiveness\n","\n","Now that the model is trained, we can get some statistics on its performance.\n","\n","While *fitting* we could see the model loss and accuracy, but how does it compare with our test set? Let's find out using [model.evaluate](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#evaluate)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HFuOKXJdMAdm"},"source":["### Evaluate the model on the test dataset\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Tw03-MK1cYId","colab":{}},"source":["model.evaluate(test_features, test_labels)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HcKEZMtCOeK-"},"source":["Notice how this returns our loss and accuracy measurements but t doesn't acutally tell us what the model predicted. For that we'll need a different function"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7Li2r1tYvW7S"},"source":["### Use the trained model to make predictions\n","\n","We've trained a model and \"proven\" that it's good—but not perfect—at classifying Iris species. Now let's use the trained model to make some predictions on our testing data. \n","\n","We will use the [predict_classes](https://www.tensorflow.org/api_docs/python/tf/keras/models/Model#predict) method and pass in our teat features. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kesTS5Lzv-M2","colab":{}},"source":["model_preds = model.predict_classes(test_features)\n","\n","print(\"Model Predictions: {}\".format(model_preds))\n","print(\"Actual Classes:    {}\".format(test_labels))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pp3gv15qKc3L","colab_type":"text"},"source":["Notice how this gives us the encoded classes (0,1,2) instead of the class names (Setosa, Versicolor, Virginica). Let's create a decoder function to convert the numbers into our labels. "]},{"cell_type":"code","metadata":{"id":"6ICMqL9-h9qD","colab_type":"code","colab":{}},"source":["def decode (labels):\n","  labels = labels.tolist()\n","  for i, val in enumerate(labels):\n","    labels[i] = class_names[val]\n","  return labels"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cUa7eL0_iBfV","colab_type":"text"},"source":["Let's run our class predictions again, this time having it print the class names. "]},{"cell_type":"code","metadata":{"id":"7a8ahK--iGpp","colab_type":"code","colab":{}},"source":["model_preds = model.predict_classes(test_features)\n","\n","#decode\n","model_preds = decode(model_preds)\n","test_labels = decode(test_labels.numpy())\n","\n","print(\"Model Predictions: {}\".format(model_preds))\n","print(\"Actual Classes:    {}\".format(test_labels))"],"execution_count":0,"outputs":[]}]}